{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-23T16:26:11.300511Z",
     "start_time": "2025-05-23T16:26:06.086814Z"
    }
   },
   "source": [
    "import re\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "input_path = './data/en/en_output_categorized.txt'\n",
    "output_path = './data/en/en_output-tmp.txt'\n",
    "n_topics = 30  # set between 20-40\n",
    "\n",
    "# Read file and extract words\n",
    "lines = []\n",
    "words = []\n",
    "numbers = []\n",
    "with open(input_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        parts = re.split(r'\\s+', line.strip())\n",
    "        if len(parts) == 3:\n",
    "            word, number, _ = parts\n",
    "            lines.append(line.strip())\n",
    "            words.append(word)\n",
    "            numbers.append(number)\n",
    "\n",
    "# Topic modeling on words\n",
    "vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 4))\n",
    "X = vectorizer.fit_transform(words)\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "lda.fit(X)\n",
    "topics = lda.transform(X)\n",
    "\n",
    "# Assign topic or UNKNOWN\n",
    "topic_labels = [f\"topic_{i}\" for i in range(n_topics)]\n",
    "assigned_topics = []\n",
    "for topic_dist in topics:\n",
    "    if topic_dist.max() < 0.1:  # threshold for UNKNOWN\n",
    "        assigned_topics.append(\"UNKNOWN\")\n",
    "    else:\n",
    "        assigned_topics.append(topic_labels[topic_dist.argmax()])\n",
    "\n",
    "# Write output\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    for word, number, topic in zip(words, numbers, assigned_topics):\n",
    "        f.write(f\"{word} {number} {topic}\\n\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T16:28:34.074888Z",
     "start_time": "2025-05-23T16:28:34.044010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_top_words = 10\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    top_features = [feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "    print(f\"Topic {topic_idx}: {' '.join(top_features)}\")"
   ],
   "id": "907a3bfc62ea7688",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: er nc ce an ra nce anc se ar rc\n",
      "Topic 1: in ti ng ing tin io ri ting pi rin\n",
      "Topic 2: oo om oc co po lo ok ot op ock\n",
      "Topic 3: ch he ro che ha es ow hes ches th\n",
      "Topic 4: se os us es ss ses pr as use ou\n",
      "Topic 5: ac ra ap es ck ack ss st as ess\n",
      "Topic 6: sh el ho els ls en sho ow ab we\n",
      "Topic 7: ar rd or rt art ear ard er ari ars\n",
      "Topic 8: la li ol ll an el ar ir ba ha\n",
      "Topic 9: ca um le ug an su mp ap ru ump\n",
      "Topic 10: ta st re sp es ec sta tar ar res\n",
      "Topic 11: ea ck ke nd an ds ic ker er and\n",
      "Topic 12: ur to or tor ou rs our ct ec ors\n",
      "Topic 13: sh he el she es ce be ic ush lt\n",
      "Topic 14: in ng ing lin li ling di ki din kin\n",
      "Topic 15: er te ter ers rs pe nt per un ters\n",
      "Topic 16: am im ra on me mp er tra ti tr\n",
      "Topic 17: ts et ke lo ets ak bl co ake le\n",
      "Topic 18: ge er ne es st te ag age ner av\n",
      "Topic 19: ff in fi fin uf uff of ass ui as\n",
      "Topic 20: ie es ies tt er te tte ter si it\n",
      "Topic 21: ll il le ns all ill ul lle ler it\n",
      "Topic 22: de er ch der us st chi nd rs ers\n",
      "Topic 23: re ee es tu ur res ure rea tur ree\n",
      "Topic 24: is la or ai no sh rn ish al ist\n",
      "Topic 25: at oa ra ate th to he ad di it\n",
      "Topic 26: al ia rt als ls ri or na le ort\n",
      "Topic 27: en nt ent me an men um pl la ant\n",
      "Topic 28: ig gh ht li igh ght st an ight is\n",
      "Topic 29: ri er ve tri iv tr ev ier ver ge\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
